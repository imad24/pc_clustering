{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(),os.pardir,os.pardir)\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir,os.pardir, 'src')\n",
    "if src_dir not in sys.path: sys.path.append(src_dir)\n",
    "\n",
    "from data.preprocessing import load_file,save_file,filter_by_season,display_df,get_scaled_series\n",
    "from features import build_features\n",
    "from visualization import visualize as viz, cluster_analysis as va\n",
    "import settings\n",
    "\n",
    "%aimport data.preprocessing\n",
    "%aimport features.build_features\n",
    "%aimport visualization.visualize\n",
    "%aimport visualization.cluster_analysis\n",
    "\n",
    "row_headers=settings.row_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"Autumn\"\n",
    "version = 99\n",
    "filename = \"nb_p2_clusters_%s\"%(season)\n",
    "filename = \"p2_clusters_%s\"%(season)\n",
    "\n",
    "\n",
    "#Load files\n",
    "raw_df = load_file(\"p2_raw\").set_index(row_headers)\n",
    "series_df =load_file(\"p2_series\",type_=\"P\",version = 1).set_index(row_headers)\n",
    "clean_df = load_file(\"p2_clean\",type_=\"P\",version = 1).set_index(row_headers)\n",
    "\n",
    "#Filter and normalize\n",
    "sclean_df = filter_by_season(clean_df,season)\n",
    "zclean_df,_ =  get_scaled_series(sclean_df)\n",
    "\n",
    "#clustering result\n",
    "cluster_df = load_file(filename,index=row_headers,type_=\"M\",version=version)\n",
    "cluster_centroid = cluster_df[[\"Cluster\",\"Centroid\"]].drop_duplicates().set_index([\"Cluster\"]).to_dict()[\"Centroid\"]\n",
    "\n",
    "plot_df = clean_df.join(cluster_df,how=\"inner\")\n",
    "\n",
    "#cleaned features\n",
    "features_df = load_file('clf_features',type_=\"P\",index = \"Product\")\n",
    "\n",
    "\n",
    "\n",
    "assert features_df is not  None\n",
    "features_df.Ldate = features_df.Ldate.apply(lambda x:str(x))\n",
    "numeric = (list(features_df.columns.to_series().groupby(features_df.dtypes).groups[np.dtype('float64')]))\n",
    "features_list = list(features_df.columns) + [\"Cluster\"]\n",
    "df = features_df.join(cluster_df,how=\"inner\")[features_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.cluster_plot(plot_df,centroid_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.centroid_grid_plot(raw_df,clean_df,cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.centroid_grid_plot(raw_df,clean_df,cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = list(set(cluster_df.Centroid))\n",
    "\n",
    "counts = cluster_df.groupby([\"Centroid\"]).count()[[\"Cluster\"]].values\n",
    "\n",
    "\n",
    "raw_profiles = series_df.loc[centroids].apply(lambda x:x/x.std(),axis=1).sort_index()\n",
    "raw_profiles[\"Count\"] = counts\n",
    "\n",
    "smoothed_profiles = clean_df.loc[centroids].apply(lambda x:x/x.std(),axis=1).sort_index()\n",
    "smoothed_profiles[\"Count\"] = counts\n",
    "\n",
    "# save_file(raw_profiles,\"profiles_%s_raw\"%season,type_=\"RP\",index=True)\n",
    "# save_file(smoothed_profiles,\"profiles_%s_smoothed\"%season,type_=\"RP\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-16 11:23:52,075 - __main__ - INFO - Load raw data file...\n",
      "2018-07-16 11:24:12,187 - __main__ - INFO - Droping uneccessary columns...\n",
      "2018-07-16 11:24:13,020 - __main__ - INFO - Setting headers info...\n",
      "2018-07-16 11:24:15,360 - __main__ - INFO - Loading products descriptions...\n",
      "2018-07-16 11:24:30,268 - __main__ - INFO - Loading clients descriptions...\n",
      "2018-07-16 11:24:30,604 - __main__ - INFO - Saving store counts file...\n",
      "2018-07-16 11:24:32,340 - __main__ - INFO - Saving clients count by product...\n"
     ]
    }
   ],
   "source": [
    "! python c:/Users/rahmim00/Documents/Notebooks/Clustering/pc_clustering/src/data/import_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-12 16:18:15,546 - __main__ - INFO - *** Making final data set from raw data ***\n",
      "2018-07-12 16:18:15,546 - __main__ - INFO - loading raw data sales file...\n",
      "2018-07-12 16:18:15,742 - __main__ - INFO - remove null sales...\n",
      "2018-07-12 16:18:15,773 - __main__ - INFO - trim empty values...\n",
      "2018-07-12 16:18:16,319 - __main__ - INFO - shit series to origin with 1 offset and range of 16 ...\n",
      "2018-07-12 16:18:17,100 - __main__ - INFO - ==> Saving raw state data to p2_raw\n",
      "2018-07-12 16:18:17,171 - __main__ - INFO - remove rare sales...\n",
      "2018-07-12 16:18:17,202 - __main__ - INFO - Smoothing the series window = 2\n",
      "2018-07-12 16:18:17,249 - __main__ - INFO - ==> Saving processed data to p2_clean\n",
      "2018-07-12 16:18:17,311 - __main__ - INFO - ==> Saving raw values data to p2_series\n"
     ]
    }
   ],
   "source": [
    "! python c:/Users/rahmim00/Documents/Notebooks/Clustering/pc_clustering/src/data/make_dataset.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-16 14:42:54,702 - __main__ - INFO - Running clustering model for <<Autumn>> version = 99...\n",
      "2018-07-16 14:42:54,821 - __main__ - INFO - Init clustering model\n",
      "2018-07-16 14:42:54,821 - __main__ - INFO - Running Hierarchical Clustering...\n",
      "2018-07-16 14:42:54,821 - __main__ - INFO - Automatic distance cut-off...\n",
      "2018-07-16 14:43:01,998 - __main__ - INFO - the number of 12 clusters has been selected\n",
      "2018-07-16 14:43:01,998 - __main__ - INFO - Training clustering model with 12 clusters\n",
      "2018-07-16 14:43:02,699 - __main__ - INFO - Model with 12 clusters successfully saved\n"
     ]
    }
   ],
   "source": [
    "! python c:/Users/rahmim00/Documents/Notebooks/Clustering/pc_clustering/src/models/train_model_clustering.py Autumn --version=99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-12 16:33:01,217 - __main__ - INFO - Load raw sales file...\n",
      "2018-07-12 16:33:01,234 - __main__ - INFO - Load product description file...\n",
      "2018-07-12 16:33:01,649 - __main__ - INFO - Load clients count  file...\n",
      "2018-07-12 16:33:01,664 - __main__ - INFO - Feature engineering...\n",
      "2018-07-12 16:33:01,913 - __main__ - INFO - ==> Saving features file to clf_features ...\n",
      "2018-07-12 16:33:01,961 - __main__ - INFO - Creating encoders...\n",
      "2018-07-12 16:33:02,099 - __main__ - INFO - Data set succefully made !\n"
     ]
    }
   ],
   "source": [
    "! python c:/Users/rahmim00/Documents/Notebooks/Clustering/pc_clustering/src/features/build_features.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-16 15:14:38,818 - __main__ - INFO - Loading data file...\n",
      "2018-07-16 15:14:38,846 - __main__ - INFO - Preparing data...\n",
      "2018-07-16 15:14:38,847 - __main__ - INFO - Encoding data...\n",
      "2018-07-16 15:14:38,847 - __main__ - INFO - Training classifier...\n",
      "2018-07-16 15:14:39,020 - __main__ - INFO - Saving classifier model to << classifier_Autumn.pkl >>...\n"
     ]
    }
   ],
   "source": [
    "! python c:/Users/rahmim00/Documents/Notebooks/Clustering/pc_clustering/src/models/train_model_classifier.py Autumn --version=99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev_py34)",
   "language": "python",
   "name": "dev_py34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
